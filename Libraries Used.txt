Libraries Used
Librosa: A Python library for audio analysis, commonly used for extracting features such as Mel-frequency cepstral coefficients (MFCCs), which are crucial for emotion recognition tasks.
NumPy: A fundamental package for numerical computations in Python, often used for handling arrays and performing mathematical operations on feature sets.
Pandas: Used for data manipulation and analysis, particularly useful for managing datasets and preprocessing steps.
Scikit-learn: A widely-used library that provides simple and efficient tools for data mining and machine learning, including implementations of various algorithms like SVM, Random Forests, and k-NN.
TensorFlow/Keras: Frameworks used for building deep learning models. Keras, which runs on top of TensorFlow, simplifies the process of creating complex neural networks such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).
Matplotlib/Seaborn: Libraries for data visualization that help in plotting confusion matrices and other graphical representations of model performance.
OpenSMILE: An open-source toolkit specifically designed for feature extraction from speech signals, often used in SER projects.
Machine Learning Algorithms Used
Support Vector Machines (SVM): Effective for classification tasks with clear margins of separation between different emotion classes. SVMs are particularly well-suited for high-dimensional spaces.
k-Nearest Neighbors (k-NN): A simple algorithm that classifies emotions based on the majority class among the k-nearest neighbors in the feature space. It is effective for smaller datasets.
Gaussian Mixture Models (GMM): Useful for modeling the distribution of features corresponding to each emotion class, allowing probabilistic classification.
Hidden Markov Models (HMM): Suitable for sequential data like speech, capturing temporal dependencies in the audio signals.
Random Forests: An ensemble learning method that builds multiple decision trees and merges their results to improve accuracy and stability in predictions.
Artificial Neural Networks (ANN): Basic neural networks that can capture complex patterns in the data, often used as a baseline model in SER tasks.
Convolutional Neural Networks (CNN): Effective for processing spectrograms or other 2D representations of audio data, capturing spatial hierarchies in features.
Recurrent Neural Networks (RNN): Particularly Long Short-Term Memory (LSTM) networks are employed to capture long-range dependencies in sequential data, making them suitable for speech analysis.
Transformers: Advanced models leveraging attention mechanisms to capture long-range dependencies without the sequential processing constraints of RNNs, increasingly being applied in SER tasksLibraries Used
Librosa: A Python library for audio analysis, commonly used for extracting features such as Mel-frequency cepstral coefficients (MFCCs), which are crucial for emotion recognition tasks.
NumPy: A fundamental package for numerical computations in Python, often used for handling arrays and performing mathematical operations on feature sets.
Pandas: Used for data manipulation and analysis, particularly useful for managing datasets and preprocessing steps.
Scikit-learn: A widely-used library that provides simple and efficient tools for data mining and machine learning, including implementations of various algorithms like SVM, Random Forests, and k-NN.
TensorFlow/Keras: Frameworks used for building deep learning models. Keras, which runs on top of TensorFlow, simplifies the process of creating complex neural networks such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).
Matplotlib/Seaborn: Libraries for data visualization that help in plotting confusion matrices and other graphical representations of model performance.
OpenSMILE: An open-source toolkit specifically designed for feature extraction from speech signals, often used in SER projects.
Machine Learning Algorithms Used
Support Vector Machines (SVM): Effective for classification tasks with clear margins of separation between different emotion classes. SVMs are particularly well-suited for high-dimensional spaces.
k-Nearest Neighbors (k-NN): A simple algorithm that classifies emotions based on the majority class among the k-nearest neighbors in the feature space. It is effective for smaller datasets.
Gaussian Mixture Models (GMM): Useful for modeling the distribution of features corresponding to each emotion class, allowing probabilistic classification.
Hidden Markov Models (HMM): Suitable for sequential data like speech, capturing temporal dependencies in the audio signals.
Random Forests: An ensemble learning method that builds multiple decision trees and merges their results to improve accuracy and stability in predictions.
Artificial Neural Networks (ANN): Basic neural networks that can capture complex patterns in the data, often used as a baseline model in SER tasks.
Convolutional Neural Networks (CNN): Effective for processing spectrograms or other 2D representations of audio data, capturing spatial hierarchies in features.
Recurrent Neural Networks (RNN): Particularly Long Short-Term Memory (LSTM) networks are employed to capture long-range dependencies in sequential data, making them suitable for speech analysis.
Transformers: Advanced models leveraging attention mechanisms to capture long-range dependencies without the sequential processing constraints of RNNs, increasingly being applied in SER tasks